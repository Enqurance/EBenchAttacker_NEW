# EBenchAttacker - A Large Language Model jailbreak evaluation tool
Hello, this is the official repository for a new version of EBenchAttacker, an evaluation tool for evaluating the alignment capabilities of LLMs under jailbreak attacks. This tool is developed by Enqurance Lin, an UG. student at Beihang University, China. The development of the tool is supported by Beijing Advanced Innovation Center for Big Data and Brain Computing. This project will continue to be updatedðŸ˜Š

## Model Supported

We list here the models supported by EBenchAttacker. Due to the heterogeneity of models, we need to gradually expand EBenchAttacker's support for different models.

- LLaMA-7B-chat-hf
- OpenAI's GPT APIs
- Anthropic's Claude APIs